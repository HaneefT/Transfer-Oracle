{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2446293e",
   "metadata": {},
   "source": [
    "Clustering/KNN with leak-free pipeline helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73193afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data_preprocessing.features import (\n",
    "    stratified_split,\n",
    "    feature_mask_from_train,\n",
    "    fit_transforms,\n",
    "    evaluate_k,\n",
    "    stability_score,\n",
    "    build_per_cluster_knn,\n",
    ")\n",
    "from src.data_preprocessing.groups import GROUPS\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config / constants\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"Rk\",\n",
    "    \"Player\",\n",
    "    \"Nation\",\n",
    "    \"Pos\",\n",
    "    \"Squad\",\n",
    "    \"Comp\",\n",
    "    \"Age\",\n",
    "    \"Born\",\n",
    "    \"MP\",\n",
    "    \"Starts\",\n",
    "    \"Min\",\n",
    "    \"90s\",\n",
    "    \"numeric_wage\",\n",
    "    \"foot\",\n",
    "    \"W\",\n",
    "    \"D\",\n",
    "    \"L\",\n",
    "]\n",
    "\n",
    "# Try to define a stable project root for saving plots\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parents[2]\n",
    "except NameError:\n",
    "    # Fallback for notebook contexts\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "PLOTS_DIR = BASE_DIR / \"plots\"\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Data + feature helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def load_position_df(pos: str) -> pd.DataFrame:\n",
    "    path = DATA_DIR / f\"players_data_{pos}_normalized.parquet\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing normalized parquet for {pos} at {path}\")\n",
    "    return pd.read_parquet(path).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def select_group_columns(df: pd.DataFrame, use_groups) -> list[str] | None:\n",
    "    if not use_groups:\n",
    "        return None\n",
    "    selected: list[str] = []\n",
    "    for g in use_groups:\n",
    "        cols = GROUPS.get(g, [])\n",
    "        selected.extend(cols)\n",
    "    selected = list(dict.fromkeys(selected))\n",
    "    return [c for c in selected if c in df.columns]\n",
    "\n",
    "\n",
    "def select_top_loading_cols(\n",
    "    train_df: pd.DataFrame,\n",
    "    base_allowed: list[str] | None,\n",
    "    top_n: int = 15,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Train-only PCA to rank raw numeric features by loading on PC1/PC2,\n",
    "    then return the union of the top_n from each component.\n",
    "    \"\"\"\n",
    "    numeric_cols = [c for c in train_df.columns if c not in CATEGORICAL_COLS]\n",
    "    if base_allowed is not None:\n",
    "        numeric_cols = [c for c in numeric_cols if c in base_allowed]\n",
    "\n",
    "    num_df = train_df[numeric_cols]\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    scaler = StandardScaler()\n",
    "    num_imp = imputer.fit_transform(num_df)\n",
    "    num_scaled = scaler.fit_transform(num_imp)\n",
    "\n",
    "    pca = PCA(random_state=42)\n",
    "    pca.fit(num_scaled)\n",
    "    comps = pca.components_\n",
    "\n",
    "    if comps.shape[0] < 2:\n",
    "        # Not enough components to rank; fall back to all numeric cols\n",
    "        return numeric_cols\n",
    "\n",
    "    loadings = pd.DataFrame(\n",
    "        comps[:2].T,\n",
    "        columns=[\"PC1\", \"PC2\"],\n",
    "        index=numeric_cols,\n",
    "    )\n",
    "    top_pc1 = loadings[\"PC1\"].abs().nlargest(top_n).index\n",
    "    top_pc2 = loadings[\"PC2\"].abs().nlargest(top_n).index\n",
    "    selected = list(dict.fromkeys(list(top_pc1) + list(top_pc2)))\n",
    "    return selected\n",
    "\n",
    "\n",
    "def sweep_k(train_X, val_X, val_df, k_grid, seed: int = 42) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for k in k_grid:\n",
    "        metrics, _, _ = evaluate_k(train_X, val_X, k, seed=seed)\n",
    "        stab = stability_score(train_X, val_X, k, seed=seed)\n",
    "        rows.append({\"k\": k, **metrics, \"stability_ari\": stab})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def choose_k(results: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Choose k by prioritizing:\n",
    "    1) higher silhouette\n",
    "    2) higher CH\n",
    "    3) lower DB\n",
    "    \"\"\"\n",
    "    scored = results.copy()\n",
    "    scored = scored.dropna(subset=[\"silhouette\"])\n",
    "    if scored.empty:\n",
    "        return int(results.iloc[0][\"k\"])\n",
    "    scored = scored.sort_values(\n",
    "        by=[\"silhouette\", \"ch\", \"db\"],\n",
    "        ascending=[False, False, True],\n",
    "    )\n",
    "    return int(scored.iloc[0][\"k\"])\n",
    "\n",
    "\n",
    "def fit_final_model(train_X, k: int, seed: int = 42) -> KMeans:\n",
    "    km = KMeans(\n",
    "        n_clusters=k,\n",
    "        n_init=20,\n",
    "        max_iter=300,\n",
    "        tol=1e-4,\n",
    "        random_state=seed,\n",
    "        algorithm=\"elkan\",\n",
    "    )\n",
    "    km.fit(train_X)\n",
    "    return km\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# KNN helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def nearest_train_neighbors(\n",
    "    km: KMeans,\n",
    "    train_X: np.ndarray,\n",
    "    train_df: pd.DataFrame,\n",
    "    test_X: np.ndarray,\n",
    "    test_df: pd.DataFrame,\n",
    "    test_labels: np.ndarray,\n",
    "    k: int = 5,\n",
    "    id_col: str = \"Player\",\n",
    "    prefer_same_foot: bool = False,\n",
    "    prefer_same_side: bool = False,\n",
    "    max_age_diff: float | None = None,\n",
    "    exclude_query_from_neighbors: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build per-cluster KNN on the training pool, then provide a callable\n",
    "    that returns top-k neighbors in train_df for any test index.\n",
    "    \"\"\"\n",
    "    per_cluster = build_per_cluster_knn(\n",
    "        train_X,\n",
    "        km.labels_,\n",
    "        n_neighbors=k + 1,\n",
    "        metric=\"cosine\",\n",
    "    )\n",
    "\n",
    "    def for_test_idx(test_idx: int) -> pd.DataFrame:\n",
    "        cluster = test_labels[test_idx]\n",
    "        nn, idx = per_cluster[int(cluster)]\n",
    "        n_q = min(k * 2, len(idx))  # grab more to allow post-filters\n",
    "\n",
    "        dists, inds = nn.kneighbors(\n",
    "            test_X[test_idx].reshape(1, -1),\n",
    "            n_neighbors=n_q,\n",
    "        )\n",
    "        global_inds = idx[inds[0]]\n",
    "\n",
    "        cols_to_show = [\n",
    "            c\n",
    "            for c in [\n",
    "                id_col,\n",
    "                \"Rk\",\n",
    "                \"Pos\",\n",
    "                \"Squad\",\n",
    "                \"Comp\",\n",
    "                \"foot\",\n",
    "                \"Age\",\n",
    "                \"Nation\",\n",
    "                \"numeric_wage\",\n",
    "            ]\n",
    "            if c in train_df.columns\n",
    "        ]\n",
    "        out = train_df.iloc[global_inds][cols_to_show].copy()\n",
    "        out[\"distance\"] = dists[0]\n",
    "        out[\"cluster\"] = cluster\n",
    "\n",
    "        query = test_df.iloc[test_idx]\n",
    "\n",
    "        # Optionally drop the query itself from its own neighbor list\n",
    "        if exclude_query_from_neighbors:\n",
    "            self_mask = np.ones(len(out), dtype=bool)\n",
    "            q_idx = getattr(query, \"name\", None)\n",
    "            if q_idx is not None:\n",
    "                self_mask &= out.index != q_idx\n",
    "            if id_col in out.columns and id_col in query.index:\n",
    "                qid = str(query[id_col]).lower()\n",
    "                self_mask &= out[id_col].astype(str).str.lower() != qid\n",
    "            out = out[self_mask]\n",
    "\n",
    "        if prefer_same_foot and \"foot\" in train_df.columns and \"foot\" in query.index:\n",
    "            qf = str(query[\"foot\"]).lower()\n",
    "            if \"foot\" in out.columns:\n",
    "                out = out[out[\"foot\"].astype(str).str.lower() == qf]\n",
    "\n",
    "        if prefer_same_side and \"Pos\" in train_df.columns and \"Pos\" in query.index:\n",
    "\n",
    "            def side(val):\n",
    "                if not isinstance(val, str):\n",
    "                    return None\n",
    "                val = val.upper()\n",
    "                if \"L\" in val:\n",
    "                    return \"L\"\n",
    "                if \"R\" in val:\n",
    "                    return \"R\"\n",
    "                return None\n",
    "\n",
    "            qs = side(query[\"Pos\"])\n",
    "            if qs is not None and \"Pos\" in out.columns:\n",
    "                out = out[out[\"Pos\"].apply(side) == qs]\n",
    "\n",
    "        if max_age_diff is not None and \"Age\" in train_df.columns and \"Age\" in query.index:\n",
    "            try:\n",
    "                qa = float(query[\"Age\"])\n",
    "                if \"Age\" in out.columns:\n",
    "                    out = out[abs(out[\"Age\"].astype(float) - qa) <= max_age_diff]\n",
    "            except (TypeError, ValueError):\n",
    "                pass\n",
    "\n",
    "        out = out.head(k)\n",
    "        return out.reset_index(drop=True)\n",
    "\n",
    "    return for_test_idx\n",
    "\n",
    "\n",
    "def self_hit_rate(\n",
    "    X: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    k: int = 5,\n",
    "    eps: float = 1e-9,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Leave-one-out self hit: for each point, query within its cluster excluding itself,\n",
    "    count a hit if the nearest neighbor is effectively identical (distance <= eps).\n",
    "    Useful to flag collapses/duplicates.\n",
    "    \"\"\"\n",
    "    per_cluster = build_per_cluster_knn(X, labels, n_neighbors=k + 1, metric=\"cosine\")\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    for _, (nn, idx) in per_cluster.items():\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        n_q = min(k + 1, len(idx))\n",
    "        dists, inds = nn.kneighbors(X[idx], n_neighbors=n_q)\n",
    "\n",
    "        for row_idx, (row_inds, row_dists) in enumerate(zip(inds, dists)):\n",
    "            global_inds = idx[row_inds]\n",
    "            mask = global_inds != idx[row_idx]\n",
    "            neighs = global_inds[mask][:k]\n",
    "            neigh_dists = row_dists[mask][:k]\n",
    "            if len(neighs) == 0:\n",
    "                continue\n",
    "            total += 1\n",
    "            if neigh_dists[0] <= eps:\n",
    "                hits += 1\n",
    "\n",
    "    return hits / total if total else np.nan\n",
    "\n",
    "\n",
    "def knn_distance_baselines(\n",
    "    X: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    df: pd.DataFrame,\n",
    "    query_idx: int,\n",
    "    k: int = 10,\n",
    "    n_random: int = 500,\n",
    "    seed: int = 42,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute simple distance-based baselines for a single query player.\n",
    "\n",
    "    Used mainly for illustrative case studies (e.g., Lamine Yamal).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = X.shape[0]\n",
    "\n",
    "    if query_idx < 0 or query_idx >= n:\n",
    "        raise IndexError(f\"query_idx {query_idx} out of bounds for X with shape {X.shape}\")\n",
    "\n",
    "    query_vec = X[query_idx].reshape(1, -1)\n",
    "    query_pos = df.loc[query_idx, \"Pos\"] if \"Pos\" in df.columns else None\n",
    "    query_cluster = labels[query_idx]\n",
    "\n",
    "    per_cluster = build_per_cluster_knn(X, labels, n_neighbors=k + 1, metric=\"cosine\")\n",
    "    nn, idx = per_cluster[int(query_cluster)]\n",
    "    n_q = min(k + 1, len(idx))\n",
    "    dists, inds = nn.kneighbors(query_vec, n_neighbors=n_q)\n",
    "    global_inds = idx[inds[0]]\n",
    "\n",
    "    mask_self = global_inds != query_idx\n",
    "    knn_dists = dists[0][mask_self][:k]\n",
    "    mean_knn_dist = float(knn_dists.mean()) if len(knn_dists) else float(\"nan\")\n",
    "\n",
    "    def random_distances(candidates: np.ndarray) -> float:\n",
    "        candidates = candidates[candidates != query_idx]\n",
    "        if len(candidates) == 0:\n",
    "            return float(\"nan\")\n",
    "        size = min(n_random, len(candidates))\n",
    "        replace = len(candidates) < n_random\n",
    "        sample_idx = rng.choice(candidates, size=size, replace=replace)\n",
    "        rand_dists = cosine_distances(query_vec, X[sample_idx])[0]\n",
    "        return float(rand_dists.mean())\n",
    "\n",
    "    same_cluster_idx = np.where(labels == query_cluster)[0]\n",
    "    mean_rand_same_cluster = random_distances(same_cluster_idx)\n",
    "\n",
    "    if query_pos is not None:\n",
    "        same_pos_idx = df.index[df[\"Pos\"] == query_pos].to_numpy()\n",
    "        mean_rand_same_pos = random_distances(same_pos_idx)\n",
    "    else:\n",
    "        mean_rand_same_pos = float(\"nan\")\n",
    "\n",
    "    all_idx = np.arange(n)\n",
    "    mean_rand_global = random_distances(all_idx)\n",
    "\n",
    "    return {\n",
    "        \"mean_knn_dist\": mean_knn_dist,\n",
    "        \"mean_rand_same_cluster\": mean_rand_same_cluster,\n",
    "        \"mean_rand_same_pos\": mean_rand_same_pos,\n",
    "        \"mean_rand_global\": mean_rand_global,\n",
    "        \"cluster\": int(query_cluster),\n",
    "        \"pos\": query_pos,\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Plotting helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _embed_2d(train_X: np.ndarray, test_X: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Ensure 2D embeddings for plotting; pad with zeros if only 1 feature.\"\"\"\n",
    "    if train_X.shape[1] >= 2:\n",
    "        return train_X[:, :2], test_X[:, :2]\n",
    "\n",
    "    def pad(arr: np.ndarray) -> np.ndarray:\n",
    "        if arr.shape[0] == 0:\n",
    "            return np.zeros((0, 2))\n",
    "        z = np.zeros((arr.shape[0], 1))\n",
    "        return np.hstack([arr, z])\n",
    "\n",
    "    return pad(train_X), pad(test_X)\n",
    "\n",
    "\n",
    "def save_cluster_plot(\n",
    "    train_X: np.ndarray,\n",
    "    test_X: np.ndarray,\n",
    "    train_labels: np.ndarray,\n",
    "    test_labels: np.ndarray,\n",
    "    pos: str,\n",
    "    path: Path,\n",
    "    highlight_points: list[dict] | None = None,\n",
    "):\n",
    "    train_emb, test_emb = _embed_2d(train_X, test_X)\n",
    "    unique_labels = np.unique(np.concatenate([train_labels, test_labels]))\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        mask_tr = train_labels == lbl\n",
    "        if mask_tr.any():\n",
    "            ax.scatter(\n",
    "                train_emb[mask_tr, 0],\n",
    "                train_emb[mask_tr, 1],\n",
    "                s=18,\n",
    "                alpha=0.6,\n",
    "                color=cmap(int(lbl) % 10),\n",
    "                label=f\"Train c{lbl}\",\n",
    "            )\n",
    "        mask_te = test_labels == lbl\n",
    "        if mask_te.any():\n",
    "            ax.scatter(\n",
    "                test_emb[mask_te, 0],\n",
    "                test_emb[mask_te, 1],\n",
    "                s=28,\n",
    "                alpha=0.9,\n",
    "                marker=\"x\",\n",
    "                color=cmap(int(lbl) % 10),\n",
    "                label=f\"Test c{lbl}\",\n",
    "            )\n",
    "\n",
    "    ax.set_title(f\"{pos} clusters (train circles, test x)\")\n",
    "    ax.set_xlabel(\"Component 1\")\n",
    "    ax.set_ylabel(\"Component 2\")\n",
    "    ax.legend(loc=\"best\", fontsize=8, ncol=2)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "    # Optional annotated highlights (e.g., worst examples)\n",
    "    if highlight_points:\n",
    "        for hp in highlight_points:\n",
    "            set_name = hp.get(\"set\")\n",
    "            idx = hp.get(\"index\")\n",
    "            label = str(hp.get(\"label\", \"\"))\n",
    "            cluster = hp.get(\"cluster\")\n",
    "            color = cmap(int(cluster) % 10) if cluster is not None else \"red\"\n",
    "            if set_name == \"train\" and idx is not None and 0 <= idx < len(train_emb):\n",
    "                x, y = train_emb[idx]\n",
    "                ax.scatter([x], [y], color=color, s=60, marker=\"o\", edgecolors=\"black\", zorder=5)\n",
    "                ax.text(x, y, label, fontsize=8, color=color, weight=\"bold\", ha=\"left\", va=\"bottom\")\n",
    "            elif set_name == \"test\" and idx is not None and 0 <= idx < len(test_emb):\n",
    "                x, y = test_emb[idx]\n",
    "                ax.scatter([x], [y], color=color, s=60, marker=\"x\", zorder=5)\n",
    "                ax.text(x, y, label, fontsize=8, color=color, weight=\"bold\", ha=\"left\", va=\"bottom\")\n",
    "\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved cluster plot to {path}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main clustering + recommendation\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_position(\n",
    "    pos: str = \"FW\",\n",
    "    k_grid: tuple[int, ...] = (2, 3, 4),\n",
    "    max_missing: float = 0.4,\n",
    "    min_variance: float = 1e-6,\n",
    "    corr_thresh: float = 0.9,\n",
    "    with_pca: float | bool = 0.95,\n",
    "    with_pca_grid: tuple[float | bool, ...] | None = None,\n",
    "    seed: int = 42,\n",
    "    use_groups=None,\n",
    "    group_presets=None,\n",
    "    include_pca_top: bool = True,\n",
    "    pca_top_n: int = 15,\n",
    "    recommend_players=None,\n",
    "    compute_graph_stats: bool = False,\n",
    "    plot_clusters: bool = False,\n",
    "    plot_path: str | None = None,\n",
    "    plot_all_pca: bool = False,\n",
    "    return_artifacts: bool = False,\n",
    "    plot_val_metrics: bool = False,\n",
    "    val_plot_dir: str | None = None,\n",
    "):\n",
    "    df = load_position_df(pos)\n",
    "\n",
    "    if isinstance(recommend_players, str):\n",
    "        recommend_players = [recommend_players]\n",
    "\n",
    "    # Leak-free split (all fitting on train only)\n",
    "    train_df, val_df, test_df = stratified_split(df, seed=seed)\n",
    "\n",
    "    combos = group_presets if group_presets else [use_groups]\n",
    "    if include_pca_top and \"pca_top\" not in combos:\n",
    "        combos = list(combos) + [\"pca_top\"]\n",
    "\n",
    "    results_summary = []\n",
    "    best_combo = None\n",
    "    best_row = None\n",
    "    best_state = None\n",
    "    runs_for_plot = []\n",
    "    # -------- Model selection phase: choose groups + PCA + k ----------\n",
    "    for combo in combos:\n",
    "        if combo == \"pca_top\":\n",
    "            base_allowed = select_group_columns(train_df, use_groups) if use_groups else None\n",
    "            allowed_numeric = select_top_loading_cols(train_df, base_allowed, top_n=pca_top_n)\n",
    "        else:\n",
    "            allowed_numeric = select_group_columns(train_df, combo)\n",
    "\n",
    "        numeric_cols = feature_mask_from_train(\n",
    "            train_df,\n",
    "            max_missing=max_missing,\n",
    "            min_variance=min_variance,\n",
    "            corr_thresh=corr_thresh,\n",
    "            allowed_numeric=allowed_numeric,\n",
    "        )\n",
    "\n",
    "        pca_options = list(with_pca_grid) if with_pca_grid is not None else [with_pca]\n",
    "        for pca_opt in pca_options:\n",
    "            try:\n",
    "                feats = fit_transforms(\n",
    "                    train_df,\n",
    "                    val_df,\n",
    "                    test_df,\n",
    "                    numeric_cols,\n",
    "                    with_pca=pca_opt,\n",
    "                    seed=seed,\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping combo {combo} with_pca={pca_opt}: {e}\")\n",
    "                continue\n",
    "\n",
    "            group_msg = f\"groups={combo}\" if combo else \"groups=all\"\n",
    "            print(f\"\\n{pos}: kept {len(numeric_cols)} numeric cols; with_pca={pca_opt}; {group_msg}\")\n",
    "            val_results = sweep_k(feats[\"X_train\"], feats[\"X_val\"], val_df, k_grid, seed=seed)\n",
    "            val_results[\"with_pca\"] = pca_opt\n",
    "            print(\"Validation metrics:\")\n",
    "            print(val_results)\n",
    "\n",
    "            best_k = choose_k(val_results)\n",
    "            chosen_row = val_results[val_results[\"k\"] == best_k].iloc[0]\n",
    "            results_summary.append(\n",
    "                {\n",
    "                    \"groups\": combo,\n",
    "                    \"with_pca\": pca_opt,\n",
    "                    \"best_k\": best_k,\n",
    "                    \"silhouette\": chosen_row[\"silhouette\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if best_row is None or chosen_row[\"silhouette\"] > best_row[\"silhouette\"]:\n",
    "                best_row = chosen_row\n",
    "                best_combo = combo\n",
    "                best_state = (numeric_cols, feats, best_k, group_msg, pca_opt)\n",
    "            if plot_clusters and plot_all_pca:\n",
    "                runs_for_plot.append(\n",
    "                    {\n",
    "                        \"numeric_cols\": numeric_cols,\n",
    "                        \"feats\": feats,\n",
    "                        \"best_k\": best_k,\n",
    "                        \"group_msg\": group_msg,\n",
    "                        \"pca_opt\": pca_opt,\n",
    "                        \"combo\": combo,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # -------- Final clustering on train split, test evaluation ----------\n",
    "    if best_state is None:\n",
    "        raise RuntimeError(\"No valid feature sets found; relax filtering thresholds or adjust group selections.\")\n",
    "    numeric_cols, feats, best_k, group_msg, best_with_pca = best_state\n",
    "    print(f\"\\nSelected combo: {group_msg} with k={best_k}; with_pca={best_with_pca}\")\n",
    "    km = fit_final_model(feats[\"X_train\"], best_k, seed=seed)\n",
    "    test_labels = km.predict(feats[\"X_test\"])\n",
    "\n",
    "    if len(np.unique(test_labels)) > 1:\n",
    "        test_sil = silhouette_score(feats[\"X_test\"], test_labels)\n",
    "        test_db = davies_bouldin_score(feats[\"X_test\"], test_labels)\n",
    "        test_ch = calinski_harabasz_score(feats[\"X_test\"], test_labels)\n",
    "    else:\n",
    "        test_sil = test_db = test_ch = np.nan\n",
    "\n",
    "    test_self_hit = np.nan\n",
    "    if compute_graph_stats:\n",
    "        test_self_hit = self_hit_rate(feats[\"X_test\"], test_labels, k=10)\n",
    "\n",
    "    print(\"\\nTest metrics:\")\n",
    "    print(\n",
    "        {\n",
    "            \"silhouette\": float(test_sil) if test_sil == test_sil else np.nan,\n",
    "            \"db\": float(test_db) if test_db == test_db else np.nan,\n",
    "            \"ch\": float(test_ch) if test_ch == test_ch else np.nan,\n",
    "            \"self_hit_at_10\": test_self_hit,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if plot_clusters:\n",
    "        try:\n",
    "            cluster_plot_path = Path(plot_path) if plot_path else PLOTS_DIR / f\"{pos}_clusters.png\"\n",
    "            save_cluster_plot(\n",
    "                feats[\"X_train\"],\n",
    "                feats[\"X_test\"],\n",
    "                km.labels_,\n",
    "                test_labels,\n",
    "                pos,\n",
    "                cluster_plot_path,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot clusters: {e}\")\n",
    "\n",
    "    if plot_clusters and plot_all_pca and runs_for_plot:\n",
    "        base_dir = (Path(plot_path).parent if plot_path else PLOTS_DIR)\n",
    "        for run in runs_for_plot:\n",
    "            try:\n",
    "                km_plot = fit_final_model(run[\"feats\"][\"X_train\"], run[\"best_k\"], seed=seed)\n",
    "                test_labels_plot = km_plot.predict(run[\"feats\"][\"X_test\"])\n",
    "                combo_tag = \"all\" if run[\"combo\"] is None else \"_\".join(run[\"combo\"])\n",
    "                pca_tag = str(run[\"pca_opt\"]).replace(\".\", \"p\")\n",
    "                fname = f\"{pos}_{combo_tag}_pca{pca_tag}_k{run['best_k']}.png\"\n",
    "                plot_out = base_dir / fname\n",
    "                save_cluster_plot(\n",
    "                    run[\"feats\"][\"X_train\"],\n",
    "                    run[\"feats\"][\"X_test\"],\n",
    "                    km_plot.labels_,\n",
    "                    test_labels_plot,\n",
    "                    pos,\n",
    "                    plot_out,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Could not plot combo {run['combo']} with_pca={run['pca_opt']}: {e}\")\n",
    "\n",
    "    # -------- Full-pool recommender (train on entire position subset) ----------\n",
    "    if recommend_players:\n",
    "        if \"Player\" not in df.columns:\n",
    "            print(\"\\nCannot build recommendations because 'Player' column is missing.\")\n",
    "        else:\n",
    "            full_num = df[numeric_cols]\n",
    "            full_imputer = SimpleImputer(strategy=\"median\")\n",
    "            full_scaler = StandardScaler()\n",
    "\n",
    "            full_imp = full_imputer.fit_transform(full_num)\n",
    "            full_scaled = full_scaler.fit_transform(full_imp)\n",
    "\n",
    "            if best_with_pca:\n",
    "                full_pca = PCA(\n",
    "                    n_components=best_with_pca,\n",
    "                    svd_solver=\"full\",\n",
    "                    random_state=seed,\n",
    "                )\n",
    "                full_scaled = full_pca.fit_transform(full_scaled)\n",
    "\n",
    "            km_full = fit_final_model(full_scaled, best_k, seed=seed)\n",
    "            full_labels = km_full.labels_\n",
    "\n",
    "            recommend_neighbors = nearest_train_neighbors(\n",
    "                km_full,\n",
    "                full_scaled,\n",
    "                df,\n",
    "                full_scaled,\n",
    "                df,\n",
    "                full_labels,\n",
    "                k=10,\n",
    "                prefer_same_foot=False,\n",
    "                prefer_same_side=False,\n",
    "                max_age_diff=None,\n",
    "                exclude_query_from_neighbors=True,\n",
    "            )\n",
    "\n",
    "            for name in recommend_players:\n",
    "                matches = df.index[df[\"Player\"].str.lower() == str(name).lower()]\n",
    "                if len(matches) == 0:\n",
    "                    print(f\"\\nNo player named '{name}' found in this position's data.\")\n",
    "                    continue\n",
    "                for idx in matches:\n",
    "                    recs = recommend_neighbors(int(idx))\n",
    "                    label = df.loc[idx, \"Player\"]\n",
    "                    print(f\"\\nRecommended train neighbors for '{label}' (full pool):\")\n",
    "                    print(recs)\n",
    "\n",
    "                    eval_stats = knn_distance_baselines(\n",
    "                        full_scaled,\n",
    "                        full_labels,\n",
    "                        df,\n",
    "                        query_idx=int(idx),\n",
    "                        k=10,\n",
    "                        n_random=500,\n",
    "                        seed=seed,\n",
    "                    )\n",
    "                    print(\"\\nKNN distance baselines for this query:\")\n",
    "                    print(eval_stats)\n",
    "\n",
    "    result = {\n",
    "        \"val_results\": results_summary,\n",
    "        \"best_combo\": best_combo,\n",
    "        \"best_k\": best_k,\n",
    "        \"best_with_pca\": best_with_pca,\n",
    "        \"test_metrics\": {\n",
    "            \"silhouette\": test_sil,\n",
    "            \"db\": test_db,\n",
    "            \"ch\": test_ch,\n",
    "            \"self_hit_at_10\": test_self_hit,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if return_artifacts:\n",
    "        result[\"artifacts\"] = {\n",
    "            \"train_df\": train_df,\n",
    "            \"val_df\": val_df,\n",
    "            \"test_df\": test_df,\n",
    "            \"numeric_cols\": numeric_cols,\n",
    "            \"feats\": feats,\n",
    "            \"labels_train\": km.labels_,\n",
    "            \"labels_test\": test_labels,\n",
    "            \"model\": km,\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Error analysis helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _cross_split_distance_baselines(\n",
    "    train_X: np.ndarray,\n",
    "    train_labels: np.ndarray,\n",
    "    train_df: pd.DataFrame,\n",
    "    test_X: np.ndarray,\n",
    "    test_labels: np.ndarray,\n",
    "    test_df: pd.DataFrame,\n",
    "    k: int = 5,\n",
    "    n_random: int = 200,\n",
    "    sample_size: int | None = 150,\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare KNN distances for test queries against random baselines drawn from the train pool.\n",
    "    Returns a DataFrame with per-query gaps for downstream summarization.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    per_cluster = build_per_cluster_knn(train_X, train_labels, n_neighbors=k + 1, metric=\"cosine\")\n",
    "    query_idx = np.arange(len(test_X))\n",
    "    if sample_size is not None and sample_size < len(query_idx):\n",
    "        query_idx = rng.choice(query_idx, size=sample_size, replace=False)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for idx in query_idx:\n",
    "        cluster = int(test_labels[idx])\n",
    "        if cluster not in per_cluster:\n",
    "            continue\n",
    "        nn, pool_idx = per_cluster[cluster]\n",
    "        n_q = min(k, len(pool_idx))\n",
    "        if n_q == 0:\n",
    "            continue\n",
    "        dists, inds = nn.kneighbors(test_X[idx].reshape(1, -1), n_neighbors=n_q)\n",
    "        knn_dists = dists[0][:k]\n",
    "        mean_knn = float(knn_dists.mean()) if len(knn_dists) else float(\"nan\")\n",
    "\n",
    "        def rand_mean(candidates: np.ndarray) -> float:\n",
    "            if len(candidates) == 0:\n",
    "                return float(\"nan\")\n",
    "            size = min(n_random, len(candidates))\n",
    "            replace = len(candidates) < n_random\n",
    "            sample_idx = rng.choice(candidates, size=size, replace=replace)\n",
    "            rand_dists = cosine_distances(test_X[idx].reshape(1, -1), train_X[sample_idx])[0]\n",
    "            return float(rand_dists.mean())\n",
    "\n",
    "        same_cluster_idx = np.where(train_labels == cluster)[0]\n",
    "        rand_same_cluster = rand_mean(same_cluster_idx)\n",
    "\n",
    "        query_pos = test_df.loc[idx, \"Pos\"] if \"Pos\" in test_df.columns else None\n",
    "        if query_pos is not None:\n",
    "            same_pos_idx = train_df.index[train_df[\"Pos\"] == query_pos].to_numpy()\n",
    "            rand_same_pos = rand_mean(same_pos_idx)\n",
    "        else:\n",
    "            rand_same_pos = float(\"nan\")\n",
    "\n",
    "        rand_global = rand_mean(np.arange(train_X.shape[0]))\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"idx\": int(idx),\n",
    "                \"player\": str(test_df.loc[idx, \"Player\"]) if \"Player\" in test_df.columns else f\"idx_{idx}\",\n",
    "                \"cluster\": cluster,\n",
    "                \"mean_knn_dist\": mean_knn,\n",
    "                \"mean_rand_same_cluster\": rand_same_cluster,\n",
    "                \"mean_rand_same_pos\": rand_same_pos,\n",
    "                \"mean_rand_global\": rand_global,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def _summarize_baseline_gaps(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Aggregate KNN-vs-random gap statistics for error analysis.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return {\n",
    "            \"n_queries\": 0,\n",
    "            \"avg_knn_dist\": float(\"nan\"),\n",
    "            \"gap_same_cluster\": {\"mean\": float(\"nan\"), \"pct_positive\": float(\"nan\")},\n",
    "            \"gap_same_pos\": {\"mean\": float(\"nan\"), \"pct_positive\": float(\"nan\")},\n",
    "            \"gap_global\": {\"mean\": float(\"nan\"), \"pct_positive\": float(\"nan\")},\n",
    "        }\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"gap_same_cluster\"] = df[\"mean_rand_same_cluster\"] - df[\"mean_knn_dist\"]\n",
    "    df[\"gap_same_pos\"] = df[\"mean_rand_same_pos\"] - df[\"mean_knn_dist\"]\n",
    "    df[\"gap_global\"] = df[\"mean_rand_global\"] - df[\"mean_knn_dist\"]\n",
    "\n",
    "    def gap_stats(col):\n",
    "        vals = df[col].dropna()\n",
    "        return {\n",
    "            \"mean\": float(vals.mean()) if len(vals) else float(\"nan\"),\n",
    "            \"pct_positive\": float((vals > 0).mean()) if len(vals) else float(\"nan\"),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"n_queries\": int(len(df)),\n",
    "        \"avg_knn_dist\": float(df[\"mean_knn_dist\"].mean()),\n",
    "        \"gap_same_cluster\": gap_stats(\"gap_same_cluster\"),\n",
    "        \"gap_same_pos\": gap_stats(\"gap_same_pos\"),\n",
    "        \"gap_global\": gap_stats(\"gap_global\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_error_analysis(\n",
    "    pos: str = \"FW\",\n",
    "    k_grid=(3, 4),\n",
    "    with_pca=2,\n",
    "    with_pca_grid: tuple[float | bool, ...] | None = None,\n",
    "    use_groups=None,\n",
    "    seed: int = 42,\n",
    "    k_neighbors: int = 10,\n",
    "    sample_size: int | None = 150,\n",
    "    n_random: int = 200,\n",
    "    plot_outliers: bool = False,\n",
    "    plot_path: str | None = None,\n",
    "    top_n_knn_outliers: int = 3,\n",
    "    outlier_method: str = \"gap\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Convenience wrapper to pick the best model for a position, then report\n",
    "    error-analysis diagnostics:\n",
    "      - self-hit rate (from run_position)\n",
    "      - distance gaps vs random baselines for sampled queries\n",
    "      - worst-case examples for qualitative inspection (by gap or by mean KNN)\n",
    "\n",
    "    If plot_outliers is True, also saves a 2D scatter with the worst examples annotated.\n",
    "    \"\"\"\n",
    "    # Ensure we also get a base cluster plot out of run_position\n",
    "    cluster_plot_path = (\n",
    "        Path(plot_path) if plot_path else PLOTS_DIR / f\"{pos}_clusters.png\"\n",
    "    )\n",
    "\n",
    "    result = run_position(\n",
    "        pos=pos,\n",
    "        k_grid=k_grid,\n",
    "        with_pca=with_pca,\n",
    "        with_pca_grid=with_pca_grid,\n",
    "        use_groups=use_groups,\n",
    "        seed=seed,\n",
    "        compute_graph_stats=True,\n",
    "        plot_clusters=True,\n",
    "        plot_path=str(cluster_plot_path),\n",
    "        plot_all_pca=False,\n",
    "        return_artifacts=True,\n",
    "    )\n",
    "    artifacts = result.get(\"artifacts\")\n",
    "    if artifacts is None:\n",
    "        raise RuntimeError(\"run_position did not return artifacts; set return_artifacts=True.\")\n",
    "\n",
    "    train_df = artifacts[\"train_df\"]\n",
    "    test_df = artifacts[\"test_df\"]\n",
    "    train_X = artifacts[\"feats\"][\"X_train\"]\n",
    "    test_X = artifacts[\"feats\"][\"X_test\"]\n",
    "    train_labels = artifacts[\"labels_train\"]\n",
    "    test_labels = artifacts[\"labels_test\"]\n",
    "\n",
    "    # KNN vs random baselines for held-out queries\n",
    "    baselines = _cross_split_distance_baselines(\n",
    "        train_X,\n",
    "        train_labels,\n",
    "        train_df,\n",
    "        test_X,\n",
    "        test_labels,\n",
    "        test_df,\n",
    "        k=k_neighbors,\n",
    "        n_random=n_random,\n",
    "        sample_size=sample_size,\n",
    "        seed=seed,\n",
    "    )\n",
    "    baseline_summary = _summarize_baseline_gaps(baselines)\n",
    "\n",
    "    # Worst cases by weakest cluster gap\n",
    "    baselines = baselines.copy()\n",
    "    baselines[\"gap_same_cluster\"] = baselines[\"mean_rand_same_cluster\"] - baselines[\"mean_knn_dist\"]\n",
    "    worst_examples = []\n",
    "    neighbors_fn = nearest_train_neighbors(\n",
    "        artifacts[\"model\"],\n",
    "        train_X,\n",
    "        train_df,\n",
    "        test_X,\n",
    "        test_df,\n",
    "        test_labels,\n",
    "        k=k_neighbors,\n",
    "    )\n",
    "\n",
    "    for _, row in baselines.nsmallest(3, \"gap_same_cluster\").iterrows():\n",
    "        neighbors = neighbors_fn(int(row[\"idx\"]))\n",
    "        worst_examples.append(\n",
    "            {\n",
    "                \"idx\": int(row[\"idx\"]),\n",
    "                \"player\": row.get(\"player\"),\n",
    "                \"cluster\": int(row[\"cluster\"]),\n",
    "                \"gap_same_cluster\": float(row[\"gap_same_cluster\"]),\n",
    "                \"mean_knn_dist\": float(row[\"mean_knn_dist\"]),\n",
    "                \"neighbors\": neighbors.to_dict(orient=\"records\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Highest mean_knn_dist outliers (regardless of gap)\n",
    "    worst_by_knn = []\n",
    "    if not baselines.empty:\n",
    "        for _, row in baselines.nlargest(top_n_knn_outliers, \"mean_knn_dist\").iterrows():\n",
    "            neighbors = neighbors_fn(int(row[\"idx\"]))\n",
    "            worst_by_knn.append(\n",
    "                {\n",
    "                    \"idx\": int(row[\"idx\"]),\n",
    "                    \"player\": row.get(\"player\"),\n",
    "                    \"cluster\": int(row[\"cluster\"]),\n",
    "                    \"mean_knn_dist\": float(row[\"mean_knn_dist\"]),\n",
    "                    \"neighbors\": neighbors.to_dict(orient=\"records\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    if plot_outliers:\n",
    "        highlights = []\n",
    "        chosen = worst_by_knn if outlier_method == \"knn\" else worst_examples\n",
    "        for ex in chosen:\n",
    "            highlights.append(\n",
    "                {\n",
    "                    \"set\": \"test\",\n",
    "                    \"index\": ex[\"idx\"],\n",
    "                    \"label\": ex.get(\"player\"),\n",
    "                    \"cluster\": ex.get(\"cluster\"),\n",
    "                }\n",
    "            )\n",
    "        out_path = (\n",
    "            Path(plot_path)\n",
    "            if plot_path\n",
    "            else PLOTS_DIR / f\"{pos}_outliers.png\"\n",
    "        )\n",
    "        try:\n",
    "            save_cluster_plot(\n",
    "                train_X,\n",
    "                test_X,\n",
    "                train_labels,\n",
    "                test_labels,\n",
    "                pos,\n",
    "                out_path,\n",
    "                highlight_points=highlights,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot outliers: {e}\")\n",
    "\n",
    "    def collect_stats(ex_list):\n",
    "        out = []\n",
    "        numeric_cols_used = artifacts.get(\"numeric_cols\", [])\n",
    "        meta_cols = [c for c in [\"Player\", \"Pos\", \"Squad\", \"Comp\"] if c in test_df.columns]\n",
    "        for ex in ex_list:\n",
    "            idx = ex[\"idx\"]\n",
    "            if 0 <= idx < len(test_df):\n",
    "                cols_to_show = meta_cols + [c for c in numeric_cols_used if c in test_df.columns]\n",
    "                row = test_df.iloc[idx][cols_to_show].to_dict()\n",
    "                out.append(\n",
    "                    {\n",
    "                        \"player\": ex.get(\"player\"),\n",
    "                        \"cluster\": ex.get(\"cluster\"),\n",
    "                        \"stats\": row,\n",
    "                    }\n",
    "                )\n",
    "        return out\n",
    "\n",
    "    worst_stats_gap = collect_stats(worst_examples)\n",
    "    worst_stats_knn = collect_stats(worst_by_knn)\n",
    "\n",
    "    if worst_stats_gap:\n",
    "        print(\"\\nWorst outlier stats (by cluster gap):\")\n",
    "        for entry in worst_stats_gap:\n",
    "            print(f\"{entry['player']} (cluster {entry['cluster']}):\")\n",
    "            print(entry[\"stats\"])\n",
    "    if worst_stats_knn:\n",
    "        print(\"\\nWorst outlier stats (by mean KNN distance):\")\n",
    "        for entry in worst_stats_knn:\n",
    "            print(f\"{entry['player']} (cluster {entry['cluster']}):\")\n",
    "            print(entry[\"stats\"])\n",
    "\n",
    "    return {\n",
    "        \"model_selection\": {\n",
    "            \"best_k\": result[\"best_k\"],\n",
    "            \"best_combo\": result[\"best_combo\"],\n",
    "            \"best_with_pca\": result[\"best_with_pca\"],\n",
    "        },\n",
    "        \"graph_metrics\": result[\"test_metrics\"],\n",
    "        \"baseline_summary\": baseline_summary,\n",
    "        \"worst_examples\": worst_examples,\n",
    "        \"worst_by_knn\": worst_by_knn,\n",
    "        \"worst_stats_gap\": worst_stats_gap,\n",
    "        \"worst_stats_knn\": worst_stats_knn,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    groups_pos = {\n",
    "        \"FW\": [\"passing\", \"goal_shot_creation\", \"pass_types\",\"misc\"],\n",
    "        \"MF\": [\"passing\", \"goal_shot_creation\", \"pass_types\", \"defensive_actions\", \"misc\"],\n",
    "        \"DF\": [\"defensive_actions\",\"possession\", \"misc\"],\n",
    "        \"GK\": [\"goalkeeping\", \"pass_types\"],\n",
    "    }\n",
    "    # run_position(\n",
    "    #     pos=\"GK\",\n",
    "    #     k_grid=3,\n",
    "    #     with_pca = 2,\n",
    "    #     group_presets=[groups_pos[\"GK\"],[\"goalkeeping\",\"pass_types\",\"misc\"],None],\n",
    "    #     compute_graph_stats=True,\n",
    "    #     plot_clusters=True,\n",
    "    #     plot_path=None,\n",
    "    #     include_pca_top=True,\n",
    "    #     return_artifacts=False,\n",
    "    #     plot_val_metrics=True,\n",
    "    # )\n",
    "    from pprint import pprint\n",
    "    for pos in [\"FW\", \"MF\", \"DF\", \"GK\"]:\n",
    "        k_vals = (3, 4, 5)\n",
    "        if pos == \"GK\":\n",
    "            k_vals = (2, 3)   \n",
    "        print(f\"\\n=== Running error analysis for position: {pos} ===\")\n",
    "        res = run_error_analysis(\n",
    "            pos=pos,\n",
    "            use_groups=groups_pos[pos],\n",
    "            k_grid=k_vals,\n",
    "            with_pca_grid=(2, 3),\n",
    "            sample_size=None,\n",
    "            k_neighbors=10,\n",
    "            top_n_knn_outliers=3,\n",
    "            outlier_method=\"knn\",\n",
    "            plot_outliers=False,\n",
    "            plot_path=None,\n",
    "        )\n",
    "        pprint(res[\"model_selection\"])\n",
    "        pprint(res[\"baseline_summary\"])\n",
    "        print(\"Worst examples by cluster gap:\")\n",
    "        pprint([{k: ex[k] for k in [\"player\", \"gap_same_cluster\", \"mean_knn_dist\"]} for ex in res[\"worst_examples\"]])\n",
    "        print(\"Worst examples by mean KNN distance:\")\n",
    "        pprint([{k: ex[k] for k in [\"player\", \"mean_knn_dist\"]} for ex in res[\"worst_by_knn\"]])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "TOvenv (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

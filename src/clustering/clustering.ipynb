{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2446293e",
   "metadata": {},
   "source": [
    "Clustering/KNN with leak-free pipeline helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6353915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.data_preprocessing.features import (\n",
    "    stratified_split,\n",
    "    feature_mask_from_train,\n",
    "    fit_transforms,\n",
    "    evaluate_k,\n",
    "    stability_score,\n",
    "    build_per_cluster_knn,\n",
    ")\n",
    "from src.data_preprocessing.groups import GROUPS\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"Rk\",\n",
    "    \"Player\",\n",
    "    \"Nation\",\n",
    "    \"Pos\",\n",
    "    \"Squad\",\n",
    "    \"Comp\",\n",
    "    \"Age\",\n",
    "    \"Born\",\n",
    "    \"MP\",\n",
    "    \"Starts\",\n",
    "    \"Min\",\n",
    "    \"90s\",\n",
    "    \"numeric_wage\",\n",
    "    \"foot\",\n",
    "    \"W\",\n",
    "    \"D\",\n",
    "    \"L\",\n",
    "]\n",
    "\n",
    "\n",
    "# Resolve data dir relative to repository root\n",
    "DATA_DIR = Path(__file__).resolve().parents[2] / \"data\" / \"processed\"\n",
    "\n",
    "\n",
    "\n",
    "def load_position_df(pos: str) -> pd.DataFrame:\n",
    "    path = DATA_DIR / f\"players_data_{pos}_normalized.parquet\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing normalized parquet for {pos} at {path}\")\n",
    "    return pd.read_parquet(path).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def select_group_columns(df: pd.DataFrame, use_groups) -> list[str] | None:\n",
    "    if not use_groups:\n",
    "        return None\n",
    "    selected = []\n",
    "    for g in use_groups:\n",
    "        cols = GROUPS.get(g, [])\n",
    "        selected.extend(cols)\n",
    "    selected = list(dict.fromkeys(selected))  # dedupe, keep order\n",
    "    return [c for c in selected if c in df.columns]\n",
    "\n",
    "\n",
    "def select_top_loading_cols(train_df: pd.DataFrame, base_allowed: list[str] | None, top_n: int = 15) -> list[str]:\n",
    "    numeric_cols = [c for c in train_df.columns if c not in CATEGORICAL_COLS]\n",
    "    if base_allowed is not None:\n",
    "        numeric_cols = [c for c in numeric_cols if c in base_allowed]\n",
    "    num_df = train_df[numeric_cols]\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    scaler = StandardScaler()\n",
    "    num_imp = imputer.fit_transform(num_df)\n",
    "    num_scaled = scaler.fit_transform(num_imp)\n",
    "    # fit PCA on train only; full rank but we only need first 2 comps\n",
    "    pca = PCA(random_state=42)\n",
    "    pca.fit(num_scaled)\n",
    "    comps = pca.components_\n",
    "    if comps.shape[0] < 2:\n",
    "        return numeric_cols  # not enough components to rank; fallback to all\n",
    "    loadings = pd.DataFrame(comps[:2].T, columns=[\"PC1\", \"PC2\"], index=numeric_cols)\n",
    "    top_pc1 = loadings[\"PC1\"].abs().nlargest(top_n).index\n",
    "    top_pc2 = loadings[\"PC2\"].abs().nlargest(top_n).index\n",
    "    selected = list(dict.fromkeys(list(top_pc1) + list(top_pc2)))\n",
    "    return selected\n",
    "\n",
    "\n",
    "def sweep_k(train_X, val_X, val_df, k_grid, seed=42):\n",
    "    rows = []\n",
    "    for k in k_grid:\n",
    "        metrics, _, _ = evaluate_k(train_X, val_X, k, seed=seed)\n",
    "        stab = stability_score(train_X, val_X, k, seed=seed)\n",
    "        rows.append({\"k\": k, **metrics, \"stability_ari\": stab})\n",
    "    res = pd.DataFrame(rows)\n",
    "    return res\n",
    "\n",
    "\n",
    "def choose_k(results):\n",
    "    # Prefer higher silhouette, then CH, then lower DB; drop NaNs\n",
    "    scored = results.copy()\n",
    "    scored = scored.dropna(subset=[\"silhouette\"])\n",
    "    if scored.empty:\n",
    "        return int(results.iloc[0][\"k\"])\n",
    "    scored = scored.sort_values(by=[\"silhouette\", \"ch\", \"db\"], ascending=[False, False, True])\n",
    "    return int(scored.iloc[0][\"k\"])\n",
    "\n",
    "\n",
    "def fit_final_model(train_X, k: int, seed=42):\n",
    "    km = KMeans(\n",
    "        n_clusters=k,\n",
    "        n_init=20,\n",
    "        max_iter=300,\n",
    "        tol=1e-4,\n",
    "        random_state=seed,\n",
    "        algorithm=\"elkan\",\n",
    "    )\n",
    "    km.fit(train_X)\n",
    "    return km\n",
    "\n",
    "\n",
    "def nearest_train_neighbors(\n",
    "    km,\n",
    "    train_X,\n",
    "    train_df,\n",
    "    test_X,\n",
    "    test_df,\n",
    "    test_labels,\n",
    "    k = 5,\n",
    "    id_col = \"Player\",\n",
    "    prefer_same_foot = False,\n",
    "    prefer_same_side = False,\n",
    "    max_age_diff = None,\n",
    "):\n",
    "    per_cluster = build_per_cluster_knn(train_X, km.labels_, n_neighbors=k + 1, metric=\"cosine\")\n",
    "\n",
    "    def for_test_idx(test_idx: int) -> pd.DataFrame:\n",
    "        cluster = test_labels[test_idx]\n",
    "        nn, idx = per_cluster[int(cluster)]\n",
    "        n_q = min(k * 2, len(idx))  # grab more to allow post-filters\n",
    "        dists, inds = nn.kneighbors(test_X[test_idx].reshape(1, -1), n_neighbors=n_q)\n",
    "        global_inds = idx[inds[0]]\n",
    "        cols_to_show = [c for c in [id_col, \"Rk\", \"Pos\", \"Squad\", \"Comp\"] if c in train_df.columns]\n",
    "        out = train_df.iloc[global_inds][cols_to_show].copy()\n",
    "        out[\"distance\"] = dists[0]\n",
    "        out[\"cluster\"] = cluster\n",
    "\n",
    "        # Post-hoc filters (optional)\n",
    "        query = test_df.iloc[test_idx]\n",
    "        if prefer_same_foot and \"foot\" in train_df.columns and \"foot\" in query:\n",
    "            qf = str(query[\"foot\"]).lower()\n",
    "            out = out[out[\"foot\"].str.lower() == qf] if \"foot\" in out.columns else out\n",
    "        if prefer_same_side and \"Pos\" in train_df.columns and \"Pos\" in query:\n",
    "            def side(val):\n",
    "                if not isinstance(val, str):\n",
    "                    return None\n",
    "                val = val.upper()\n",
    "                if \"L\" in val:\n",
    "                    return \"L\"\n",
    "                if \"R\" in val:\n",
    "                    return \"R\"\n",
    "                return None\n",
    "            qs = side(query[\"Pos\"])\n",
    "            if qs is not None and \"Pos\" in out.columns:\n",
    "                out = out[out[\"Pos\"].apply(side) == qs]\n",
    "        if max_age_diff is not None and \"Age\" in train_df.columns and \"Age\" in query:\n",
    "            try:\n",
    "                qa = float(query[\"Age\"])\n",
    "                out = out[abs(out[\"Age\"].astype(float) - qa) <= max_age_diff] if \"Age\" in out.columns else out\n",
    "            except (TypeError, ValueError):\n",
    "                pass\n",
    "\n",
    "        out = out.head(k)\n",
    "        return out.reset_index(drop=True)\n",
    "\n",
    "    return for_test_idx\n",
    "\n",
    "\n",
    "def knn_reciprocity_stats(X: np.ndarray, labels: np.ndarray, k: int = 5) -> dict:\n",
    "    \"\"\"Simple KNN graph stats on a given split (uses that split as both query and pool).\"\"\"\n",
    "    per_cluster = build_per_cluster_knn(X, labels, n_neighbors=k + 1, metric=\"cosine\")\n",
    "    total = 0\n",
    "    mutual = 0\n",
    "    mean_kth_dist = []\n",
    "    for _, (nn, idx) in per_cluster.items():\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        n_q = min(k + 1, len(idx))\n",
    "        dists, inds = nn.kneighbors(X[idx], n_neighbors=n_q)\n",
    "        for row_idx, (row_inds, row_dists) in enumerate(zip(inds, dists)):\n",
    "            global_inds = idx[row_inds]\n",
    "            mask = global_inds != idx[row_idx]\n",
    "            neighs = global_inds[mask][:k]\n",
    "            neigh_dists = row_dists[mask][:k]\n",
    "            if len(neighs) == 0:\n",
    "                continue\n",
    "            total += len(neighs)\n",
    "            mean_kth_dist.append(neigh_dists[-1])\n",
    "            for n in neighs:\n",
    "                n_neighbors = idx[inds[nn.kneighbors(X[n].reshape(1, -1), n_neighbors=n_q)[1][0]]]\n",
    "                if idx[row_idx] in n_neighbors[1:]:  # exclude self at [0]\n",
    "                    mutual += 1\n",
    "    reciprocity = mutual / total if total else np.nan\n",
    "    return {\n",
    "        \"reciprocity\": reciprocity,\n",
    "        \"mean_kth_dist\": float(np.mean(mean_kth_dist)) if mean_kth_dist else np.nan,\n",
    "    }\n",
    "\n",
    "\n",
    "def self_hit_rate(X: np.ndarray, labels: np.ndarray, k: int = 5, eps: float = 1e-9) -> float:\n",
    "    \"\"\"\n",
    "    Leave-one-out self hit: for each point, query within its cluster excluding itself,\n",
    "    count a hit if the nearest neighbor is effectively identical (distance <= eps).\n",
    "    Useful to flag collapses/duplicates.\n",
    "    \"\"\"\n",
    "    per_cluster = build_per_cluster_knn(X, labels, n_neighbors=k + 1, metric=\"cosine\")\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    for _, (nn, idx) in per_cluster.items():\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        n_q = min(k + 1, len(idx))\n",
    "        dists, inds = nn.kneighbors(X[idx], n_neighbors=n_q)\n",
    "        for row_idx, (row_inds, row_dists) in enumerate(zip(inds, dists)):\n",
    "            global_inds = idx[row_inds]\n",
    "            mask = global_inds != idx[row_idx]\n",
    "            neighs = global_inds[mask][:k]\n",
    "            neigh_dists = row_dists[mask][:k]\n",
    "            if len(neighs) == 0:\n",
    "                continue\n",
    "            total += 1\n",
    "            if neigh_dists[0] <= eps:\n",
    "                hits += 1\n",
    "    return hits / total if total else np.nan\n",
    "\n",
    "\n",
    "def run_position(\n",
    "    pos=\"FW\",\n",
    "    k_grid=(2, 3, 4),\n",
    "    max_missing=0.4,\n",
    "    min_variance=1e-6,\n",
    "    corr_thresh=0.9,\n",
    "    with_pca=0.95,\n",
    "    seed=42,\n",
    "    use_groups=None,\n",
    "    group_presets=None,\n",
    "    include_pca_top=False,\n",
    "    pca_top_n=15,\n",
    "):\n",
    "    df = load_position_df(pos)\n",
    "    train_df, val_df, test_df = stratified_split(df, seed=seed)\n",
    "\n",
    "    combos = group_presets if group_presets else [use_groups]\n",
    "    if include_pca_top and \"pca_top\" not in combos:\n",
    "        combos = list(combos) + [\"pca_top\"]\n",
    "    results_summary = []\n",
    "    best_combo = None\n",
    "    best_row = None\n",
    "    best_state = None\n",
    "\n",
    "    for combo in combos:\n",
    "        if combo == \"pca_top\":\n",
    "            base_allowed = select_group_columns(train_df, use_groups) if use_groups else None\n",
    "            allowed_numeric = select_top_loading_cols(train_df, base_allowed, top_n=pca_top_n)\n",
    "        else:\n",
    "            allowed_numeric = select_group_columns(train_df, combo)\n",
    "        numeric_cols = feature_mask_from_train(\n",
    "            train_df,\n",
    "            max_missing=max_missing,\n",
    "            min_variance=min_variance,\n",
    "            corr_thresh=corr_thresh,\n",
    "            allowed_numeric=allowed_numeric,\n",
    "        )\n",
    "        feats = fit_transforms(\n",
    "            train_df,\n",
    "            val_df,\n",
    "            test_df,\n",
    "            numeric_cols,\n",
    "            with_pca=with_pca,\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "        group_msg = f\"groups={combo}\" if combo else \"groups=all\"\n",
    "        print(f\"\\n{pos}: kept {len(numeric_cols)} numeric cols; with_pca={with_pca}; {group_msg}\")\n",
    "        val_results = sweep_k(feats[\"X_train\"], feats[\"X_val\"], val_df, k_grid, seed=seed)\n",
    "        print(\"Validation metrics:\")\n",
    "        print(val_results)\n",
    "\n",
    "        best_k = choose_k(val_results)\n",
    "        chosen_row = val_results[val_results[\"k\"] == best_k].iloc[0]\n",
    "        results_summary.append({\"groups\": combo, \"best_k\": best_k, \"silhouette\": chosen_row[\"silhouette\"]})\n",
    "\n",
    "        if best_row is None or chosen_row[\"silhouette\"] > best_row[\"silhouette\"]:\n",
    "            best_row = chosen_row\n",
    "            best_combo = combo\n",
    "            best_state = (numeric_cols, feats, best_k, group_msg)\n",
    "\n",
    "    # Train/test on best combo\n",
    "    numeric_cols, feats, best_k, group_msg = best_state\n",
    "    print(f\"\\nSelected combo: {group_msg} with k={best_k}\")\n",
    "    km = fit_final_model(feats[\"X_train\"], best_k, seed=seed)\n",
    "    test_labels = km.predict(feats[\"X_test\"])\n",
    "    if len(np.unique(test_labels)) > 1:\n",
    "        test_sil = silhouette_score(feats[\"X_test\"], test_labels)\n",
    "        test_db = davies_bouldin_score(feats[\"X_test\"], test_labels)\n",
    "        test_ch = calinski_harabasz_score(feats[\"X_test\"], test_labels)\n",
    "    else:\n",
    "        test_sil = test_db = test_ch = np.nan\n",
    "\n",
    "    print(\"\\nTest metrics:\")\n",
    "    test_knn_stats = knn_reciprocity_stats(feats[\"X_test\"], test_labels, k=10)\n",
    "    test_self_hit = self_hit_rate(feats[\"X_test\"], test_labels, k=10)\n",
    "    print(\n",
    "        {\n",
    "            \"silhouette\": float(test_sil) if test_sil == test_sil else np.nan,\n",
    "            \"db\": float(test_db) if test_db == test_db else np.nan,\n",
    "            \"ch\": float(test_ch) if test_ch == test_ch else np.nan,\n",
    "            **test_knn_stats,\n",
    "            \"self_hit_at_10\": test_self_hit,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    neighbors_fn = nearest_train_neighbors(\n",
    "        km,\n",
    "        feats[\"X_train\"],\n",
    "        train_df,\n",
    "        feats[\"X_test\"],\n",
    "        test_df,\n",
    "        test_labels,\n",
    "        k=5,\n",
    "        prefer_same_foot=False,\n",
    "        prefer_same_side=False,\n",
    "        max_age_diff=None,\n",
    "    )\n",
    "    # Example: show neighbors for first test row if available\n",
    "    if len(test_df) > 0:\n",
    "        example = neighbors_fn(0)\n",
    "        print(\"\\nNearest train neighbors for first test player:\")\n",
    "        print(example)\n",
    "    return {\n",
    "        \"val_results\": results_summary,\n",
    "        \"best_combo\": best_combo,\n",
    "        \"best_k\": best_k,\n",
    "        \"test_metrics\": {\n",
    "            \"silhouette\": test_sil,\n",
    "            \"db\": test_db,\n",
    "            \"ch\": test_ch,\n",
    "            **test_knn_stats,\n",
    "            \"self_hit_at_10\": test_self_hit,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_position(\n",
    "    pos=\"FW\",\n",
    "    k_grid=(3,4),\n",
    "    with_pca=0.6,           \n",
    "    include_pca_top=True,  \n",
    "    pca_top_n=15,\n",
    "    group_presets=[None, [\"goal_shot_creation\"],[\"passing\", \"goal_shot_creation\"],[\"passing\", \"goal_shot_creation\", \"pass_types\", \"possession\"],\n",
    "                   [\"passing\", \"goal_shot_creation\", \"pass_types\", \"possession\", \"defense\",\"misc\"]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "TOvenv (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
